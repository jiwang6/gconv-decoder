{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Impor tensorflow and numpy\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import math as m\n",
    "import time\n",
    "# For validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "# For plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Add the library to the system path\n",
    "import os,sys\n",
    "se2cnn_source =  os.path.join(os.getcwd(),'..')\n",
    "if se2cnn_source not in sys.path:\n",
    "    sys.path.append(se2cnn_source)\n",
    "\n",
    "# Import the library\n",
    "import se2cnn.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1523519337201949708\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9848225792\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4721537981234494761\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:06:00.0, compute capability: 8.9\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# check tf can see the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier's/He-Rang-Zhen-Sun initialization for layers that are followed ReLU\n",
    "def weight_initializer(n_in, n_out):\n",
    "    return tf.random_normal_initializer(mean=0.0, stddev=m.sqrt(2.0 / (n_in))\n",
    "    )\n",
    "\n",
    "def size_of(tensor) :\n",
    "    # Multiply elements one by one\n",
    "    result = 1\n",
    "    for x in tensor.get_shape().as_list():\n",
    "         result = result * x \n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nontest_data_2D.shape = (60000, 7, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "code_distance = 7\n",
    "\n",
    "error_rate = 0.1\n",
    "\n",
    "observations = 70000\n",
    "\n",
    "dataset = np.load(f'test-datasets/HL_data_{code_distance}_{int(error_rate*100)}_{observations}.npy')\n",
    "\n",
    "non_test, test = np.split(dataset, [60000])\n",
    "\n",
    "non_test_data = non_test[:, :code_distance**2 *2]\n",
    "# last 4 columns are the labels\n",
    "nontest_labels= non_test[:, -4:]\n",
    "\n",
    "test_data = test[:, :code_distance**2 *2]\n",
    "test_labels= test[:, -4:]\n",
    "\n",
    "# Reshape to 2D multi-channel images\n",
    "nontest_data_2D = non_test_data.reshape(len(non_test_data), code_distance, code_distance*2,1) # data shape here\n",
    "test_data_2D = test_data.reshape(len(test_data), code_distance, code_distance*2,1)\n",
    "\n",
    "print(f\"nontest_data_2D.shape = {nontest_data_2D.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 11, 18, 1) (10000, 11, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "# pad data #todo: make this reflect closed surfacec\n",
    "\n",
    "nontest_data_2D = np.pad(nontest_data_2D,((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=((0,0),(0,0),(0,0),(0,0)))\n",
    "test_data_2D = np.pad(test_data_2D,((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=((0,0),(0,0),(0,0),(0,0)))\n",
    "\n",
    "print(nontest_data_2D.shape, test_data_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from Datavis import visualize_observation\n",
    "\n",
    "# visualizing observation and label\n",
    "# red: x-error, yellow: z-error, green: x and z error, blue: stabilizer activation\n",
    "\n",
    "observation_index = 69\n",
    "\n",
    "visualize_observation(non_test[observation_index][:-4])\n",
    "print(non_test[observation_index][-4:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-hot encode all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import eye\n",
    "imat = eye(16).toarray()\n",
    "# convert to integer matrix\n",
    "imat = imat.astype(int)\n",
    "\n",
    "encoding_dict = {}\n",
    "for i in range(0,16):\n",
    "    # convert to numpy array\n",
    "    encoding_dict[i] = np.array(imat[15-i])\n",
    "\n",
    "# do that for all entries in nontest_labels\n",
    "nontest_labels_encoded = np.argmax(np.array([encoding_dict[int(''.join(map(str,single_label)),2)] for single_label in nontest_labels]), axis=1)\n",
    "\n",
    "\n",
    "test_labels_encoded = np.argmax(np.array([encoding_dict[int(''.join(map(str,single_label)),2)] for single_label in test_labels]), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GCNN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 11, 18, 1)\n",
      "(?,)\n"
     ]
    }
   ],
   "source": [
    "Ntheta = 4 # Kernel size in angular direction\n",
    "Nxy = 3      # Kernel size in spatial direction\n",
    "Nc = 8      # Number of channels in the initial layer\n",
    "\n",
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "inputs_ph = tf.placeholder( dtype = tf.float32, shape = [None, code_distance + 4, 2*code_distance + 4, 1] ) # data shape here\n",
    "labels_ph = tf.placeholder( dtype = tf.int32, shape = [None,] )\n",
    "\n",
    "print(inputs_ph.shape)\n",
    "print(labels_ph.shape)\n",
    "\n",
    "tensor_in = inputs_ph\n",
    "Nc_in = 1\n",
    "\n",
    "kernels={}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z2-SE2N BASE KERNEL SHAPE: (3, 3, 1, 8)\n",
      "Z2-SE2N ROTATED KERNEL SET SHAPE: (4, 3, 3, 1, 8)\n",
      "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 9, 16, 4, 8)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"Layer_{}\".format(1)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = Nc\n",
    "\n",
    "    ## Perform lifting convolution\n",
    "    # The kernels used in the lifting layer\n",
    "    kernels_raw = tf.get_variable(\n",
    "                        'kernel', \n",
    "                        [Nxy,Nxy,Nc_in,Nc_out],\n",
    "                        initializer=weight_initializer(Nxy*Nxy*Nc_in,Nc_out))\n",
    "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
    "    bias = tf.get_variable( # Same bias for all orientations\n",
    "                        \"bias\",\n",
    "                        [1, 1, 1, 1, Nc_out], \n",
    "                        initializer=tf.constant_initializer(value=0.01))\n",
    "    # Lifting layer\n",
    "    tensor_out, kernels_formatted = se2cnn.layers.z2_se2n(\n",
    "                            input_tensor = tensor_in,\n",
    "                            kernel = kernels_raw,\n",
    "                            orientations_nb = Ntheta)\n",
    "    # Add bias\n",
    "    tensor_out = tensor_out + bias\n",
    "    \n",
    "    ## Apply ReLU\n",
    "    tensor_out = tf.nn.relu(tensor_out)\n",
    "\n",
    "    ## Prepare for the next layer\n",
    "    tensor_in = tensor_out\n",
    "    Nc_in = Nc_out\n",
    "    \n",
    "    ## Save kernels for inspection\n",
    "    kernels[_scope.name] = kernels_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 9, 16, 4, 8)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_in.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE2N-SE2N BASE KERNEL SHAPE: (3, 3, 4, 8, 16)\n",
      "SE2N-SE2N ROTATED KERNEL SET SHAPE: (4, 3, 3, 4, 8, 16)\n",
      "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 7, 14, 4, 16)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"Layer_{}\".format(2)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = 2*Nc\n",
    "\n",
    "    ## Perform group convolution\n",
    "    # The kernels used in the group convolution layer\n",
    "    kernels_raw = tf.get_variable(\n",
    "                        'kernel', \n",
    "                        [Nxy,Nxy,Ntheta,Nc_in,Nc_out],\n",
    "                        initializer=weight_initializer(Nxy*Nxy*Ntheta*Nc_in,Nc_out))\n",
    "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
    "    bias = tf.get_variable( # Same bias for all orientations\n",
    "                        \"bias\",\n",
    "                        [1, 1, 1, 1, Nc_out], \n",
    "                        initializer=tf.constant_initializer(value=0.01))\n",
    "    # The group convolution layer\n",
    "    tensor_out, kernels_formatted = se2cnn.layers.se2n_se2n(\n",
    "                            input_tensor = tensor_in,\n",
    "                            kernel = kernels_raw)\n",
    "    tensor_out = tensor_out + bias\n",
    "\n",
    "    \n",
    "    ## Apply ReLU\n",
    "    tensor_out = tf.nn.relu(tensor_out)\n",
    "\n",
    "    ## Prepare for the next layer\n",
    "    tensor_in = tensor_out\n",
    "    Nc_in = Nc_out\n",
    "    \n",
    "    ## Save kernels for inspection\n",
    "    kernels[_scope.name] = kernels_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE2N-SE2N BASE KERNEL SHAPE: (3, 3, 4, 16, 32)\n",
      "SE2N-SE2N ROTATED KERNEL SET SHAPE: (4, 3, 3, 4, 16, 32)\n",
      "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 5, 12, 4, 32)\n"
     ]
    }
   ],
   "source": [
    "# 2D convolution layer\n",
    "with tf.variable_scope(\"Layer_{}\".format(3)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = 4*Nc\n",
    "\n",
    "    ## Perform group convolution\n",
    "    # The kernels used in the group convolution layer\n",
    "    kernels_raw = tf.get_variable(\n",
    "                        'kernel', \n",
    "                        [Nxy,Nxy,Ntheta,Nc_in,Nc_out],\n",
    "                        initializer=weight_initializer(Nxy*Nxy*Ntheta*Nc_in,Nc_out))\n",
    "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
    "    bias = tf.get_variable( # Same bias for all orientations\n",
    "                        \"bias\",\n",
    "                        [1, 1, 1, 1, Nc_out], \n",
    "                        initializer=tf.constant_initializer(value=0.01))\n",
    "    # The group convolution layer\n",
    "    tensor_out, kernels_formatted = se2cnn.layers.se2n_se2n(\n",
    "                            input_tensor = tensor_in,\n",
    "                            kernel = kernels_raw)\n",
    "    tensor_out = tensor_out + bias\n",
    "    \n",
    "    ## Apply ReLU\n",
    "    tensor_out = tf.nn.relu(tensor_out)\n",
    "\n",
    "    ## Prepare for the next layer\n",
    "    tensor_in = tensor_out\n",
    "    Nc_in = Nc_out\n",
    "    \n",
    "    ## Save kernels for inspection\n",
    "    kernels[_scope.name] = kernels_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE2N-SE2N BASE KERNEL SHAPE: (3, 3, 4, 32, 128)\n",
      "SE2N-SE2N ROTATED KERNEL SET SHAPE: (4, 3, 3, 4, 32, 128)\n",
      "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 3, 10, 4, 128)\n"
     ]
    }
   ],
   "source": [
    "# 2D convolution layer\n",
    "with tf.variable_scope(\"Layer_{}\".format(4)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = 128\n",
    "\n",
    "    ## Perform group convolution\n",
    "    # The kernels used in the group convolution layer\n",
    "    kernels_raw = tf.get_variable(\n",
    "                        'kernel', \n",
    "                        [Nxy,Nxy,Ntheta,Nc_in,Nc_out],\n",
    "                        initializer=weight_initializer(Nxy*Nxy*Ntheta*Nc_in,Nc_out))\n",
    "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
    "    bias = tf.get_variable( # Same bias for all orientations\n",
    "                        \"bias\",\n",
    "                        [1, 1, 1, 1, Nc_out], \n",
    "                        initializer=tf.constant_initializer(value=0.01))\n",
    "    # Convolution layer\n",
    "    # The group convolution layer\n",
    "    tensor_out, kernels_formatted = se2cnn.layers.se2n_se2n(\n",
    "                            input_tensor = tensor_in,\n",
    "                            kernel = kernels_raw)\n",
    "    tensor_out = tensor_out + bias\n",
    "    \n",
    "    ## Apply ReLU\n",
    "    tensor_out = tf.nn.relu(tensor_out)\n",
    "\n",
    "    ## Prepare for the next layer\n",
    "    tensor_in = tensor_out\n",
    "    Nc_in = Nc_out\n",
    "    \n",
    "    ## Save kernels for inspection\n",
    "    kernels[_scope.name] = kernels_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(3), Dimension(10), Dimension(4), Dimension(128)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Layer_{}\".format(5)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = 16\n",
    "\n",
    "    ## Perform group convolution\n",
    "    # The kernels used in the group convolution layer\n",
    "    kernels_raw = tf.get_variable(\n",
    "                        'kernel', \n",
    "                        [1,1,Nc_in,Nc_out],\n",
    "                        initializer=weight_initializer(1*1*Nc_in,Nc_out))\n",
    "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
    "    bias = tf.get_variable( # Same bias for all orientations\n",
    "                        \"bias\",\n",
    "                        [1, 1, 1, Nc_out], \n",
    "                        initializer=tf.constant_initializer(value=0.01))\n",
    "\n",
    "    \n",
    "    ## Convolution layer\n",
    "    tensor_out = tf.nn.conv2d(\n",
    "                        input = tensor_in,\n",
    "                        filter=kernels_raw,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding=\"VALID\")\n",
    "    tensor_out = tensor_out + bias\n",
    "\n",
    "    tensor_out= tf.reduce_max(tensor_out, axis=1)\n",
    "    \n",
    "    ## The output logits\n",
    "    logits = tensor_out[:,0,0,:]\n",
    "    predictions = tf.argmax(input=logits, axis=1)\n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "    \n",
    "    ## Save the kernels for later inspection\n",
    "    kernels[_scope.name] = kernels_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(16)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "must match: (?,) and (?, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f\"must match: {labels_ph.shape} and {logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels_ph, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "RAW kernel shapes:\n",
      "[Layer_1/kernel:0]: (3, 3, 1, 8), total nr of weights = 72\n",
      "[Layer_2/kernel:0]: (3, 3, 4, 8, 16), total nr of weights = 4608\n",
      "[Layer_3/kernel:0]: (3, 3, 4, 16, 32), total nr of weights = 18432\n",
      "[Layer_4/kernel:0]: (3, 3, 4, 32, 128), total nr of weights = 147456\n",
      "[Layer_5/kernel:0]: (1, 1, 128, 16), total nr of weights = 2048\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "#-- Define the l2 loss \n",
    "weightDecay=5e-4\n",
    "# Get the raw kernels\n",
    "variables_wd = tf.get_collection('raw_kernels')\n",
    "print('-----')\n",
    "print('RAW kernel shapes:')\n",
    "for v in variables_wd: print( \"[{}]: {}, total nr of weights = {}\".format(v.name, v.get_shape(), size_of(v)))\n",
    "print('-----')\n",
    "loss_l2 = weightDecay*sum([tf.nn.l2_loss(ker) for ker in variables_wd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Training Op (for TRAIN mode)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "train_op = optimizer.minimize(\n",
    "    loss=loss + loss_l2,\n",
    "    global_step=tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Start the (GPU) session\n",
    "initializer = tf.global_variables_initializer()\n",
    "session = tf.Session(graph=tf.get_default_graph()) #-- Session created\n",
    "session.run(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "n_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: logits and labels must have the same first dimension, got logits shape [100,16] and labels shape [60000]\n\t [[node sparse_softmax_cross_entropy_loss/xentropy/xentropy (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\2633372275.py:2) ]]\n\t [[sparse_softmax_cross_entropy_loss/value/_17]]\n  (1) Invalid argument: logits and labels must have the same first dimension, got logits shape [100,16] and labels shape [60000]\n\t [[node sparse_softmax_cross_entropy_loss/xentropy/xentropy (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\2633372275.py:2) ]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_softmax_cross_entropy_loss/xentropy/xentropy:\n Placeholder_1 (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\1968823558.py:10)\t\n Layer_5/strided_slice (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\1508825133.py:29)\n\nInput Source operations connected to node sparse_softmax_cross_entropy_loss/xentropy/xentropy:\n Placeholder_1 (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\1968823558.py:10)\t\n Layer_5/strided_slice (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\1508825133.py:29)\n\nOriginal stack trace for 'sparse_softmax_cross_entropy_loss/xentropy/xentropy':\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n    app.start()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n    self.io_loop.start()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n    await self.process_one()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n    await dispatch(*args)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n    await result\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n    reply_content = await reply_content\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n    result = self._run_cell(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n    result = runner(coro)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\2633372275.py\", line 2, in <module>\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels_ph, logits=logits)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py\", line 1004, in sparse_softmax_cross_entropy\n    losses = nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4262, in sparse_softmax_cross_entropy_with_logits\n    cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 11258, in sparse_softmax_cross_entropy_with_logits\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1375\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1359\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1451\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1450\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1451\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1452\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1453\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: logits and labels must have the same first dimension, got logits shape [100,16] and labels shape [60000]\n\t [[{{node sparse_softmax_cross_entropy_loss/xentropy/xentropy}}]]\n\t [[sparse_softmax_cross_entropy_loss/value/_17]]\n  (1) Invalid argument: logits and labels must have the same first dimension, got logits shape [100,16] and labels shape [60000]\n\t [[{{node sparse_softmax_cross_entropy_loss/xentropy/xentropy}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NItPerEpoch):\n\u001b[0;32m     11\u001b[0m     feed_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m             inputs_ph: np\u001b[38;5;241m.\u001b[39marray(data[samples[iteration\u001b[38;5;241m*\u001b[39mbatch_size:(iteration\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size]]),\n\u001b[0;32m     13\u001b[0m             labels_ph: np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m     14\u001b[0m             }\n\u001b[1;32m---> 15\u001b[0m     operators_output \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_op\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     loss_average \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m operators_output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39mNItPerEpoch\n\u001b[0;32m     17\u001b[0m tElapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tStart\n",
      "File \u001b[1;32mc:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    964\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    970\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1190\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1193\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1368\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1394\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly supports NHWC tensor format\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[0;32m   1390\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1391\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1392\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1393\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1394\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: logits and labels must have the same first dimension, got logits shape [100,16] and labels shape [60000]\n\t [[node sparse_softmax_cross_entropy_loss/xentropy/xentropy (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\2633372275.py:2) ]]\n\t [[sparse_softmax_cross_entropy_loss/value/_17]]\n  (1) Invalid argument: logits and labels must have the same first dimension, got logits shape [100,16] and labels shape [60000]\n\t [[node sparse_softmax_cross_entropy_loss/xentropy/xentropy (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\2633372275.py:2) ]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_softmax_cross_entropy_loss/xentropy/xentropy:\n Placeholder_1 (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\1968823558.py:10)\t\n Layer_5/strided_slice (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\1508825133.py:29)\n\nInput Source operations connected to node sparse_softmax_cross_entropy_loss/xentropy/xentropy:\n Placeholder_1 (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\1968823558.py:10)\t\n Layer_5/strided_slice (defined at C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\1508825133.py:29)\n\nOriginal stack trace for 'sparse_softmax_cross_entropy_loss/xentropy/xentropy':\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n    app.start()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n    self.io_loop.start()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n    await self.process_one()\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n    await dispatch(*args)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n    await result\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n    reply_content = await reply_content\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n    result = self._run_cell(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n    result = runner(coro)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\jimzw\\AppData\\Local\\Temp\\ipykernel_27244\\2633372275.py\", line 2, in <module>\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels_ph, logits=logits)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py\", line 1004, in sparse_softmax_cross_entropy\n    losses = nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 4262, in sparse_softmax_cross_entropy_with_logits\n    cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 11258, in sparse_softmax_cross_entropy_with_logits\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"c:\\Users\\jimzw\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "for epoch_nr in range(n_epochs):\n",
    "    loss_average = 0\n",
    "    data = nontest_data_2D\n",
    "    labels = nontest_labels_encoded\n",
    "    # KBatch settings\n",
    "    NItPerEpoch = m.floor(len(data)/batch_size) #number of iterations per epoch\n",
    "    samples=np.random.permutation(len(data))\n",
    "    # Loop over dataset\n",
    "    tStart = time.time()\n",
    "    for iteration in range(NItPerEpoch):\n",
    "        feed_dict = {\n",
    "                inputs_ph: np.array(data[samples[iteration*batch_size:(iteration+1)*batch_size]]),\n",
    "                labels_ph: np.array(labels[samples[iteration*batch_size:(iteration+1)*batch_size]])\n",
    "                }\n",
    "        operators_output = session.run([ loss , train_op ], feed_dict)\n",
    "        loss_average += operators_output[0]/NItPerEpoch\n",
    "    tElapsed = time.time() - tStart\n",
    "    print('Epoch ' , epoch_nr , ' finished... Average loss = ' , round(loss_average,4) , ', time = ',round(tElapsed,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "labels_pred = []\n",
    "for i in range(round(len(test_data_2D)/batch_size)):\n",
    "    [ labels_pred_batch ] = session.run([ predictions ], { inputs_ph: test_data_2D[i*batch_size:(i+1)*batch_size] })\n",
    "    labels_pred = labels_pred + list(labels_pred_batch)\n",
    "labels_pred = np.array(labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_pred[0:10])\n",
    "print(test_labels_encoded[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((labels_pred - test_labels_encoded)**2==0).astype(float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((labels_pred - test_labels_encoded)**2>0).astype(float).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*((labels_pred - test_labels_encoded)**2>0).astype(float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels_encoded, labels_pred)\n",
    "plot_confusion_matrix(cm, range(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
